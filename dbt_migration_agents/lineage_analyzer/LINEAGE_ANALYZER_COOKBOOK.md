# Lineage Analyzer Cookbook

## Overview

This cookbook provides the methodology for analyzing DBT model dependencies and generating comprehensive migration analysis documents.

**Important**: This cookbook is for **analyzing pre-generated lineage files** to create migration plans. Lineage files are generated separately using Python scripts:
- **DBT lineage**: `lineage_analyzer/dbt_based/analyze_dbt_lineage.py`
- **BigQuery lineage** (optional): `lineage_analyzer/dataplex_based/analyze_bq_lineage.py`

## Configuration

**CRITICAL**: All project-specific values come from `config/migration_config.yaml`.

Before using this cookbook, ensure the config file is properly set up.

## Purpose

The Lineage Analyzer:
1. Reads pre-generated DBT lineage files (required)
2. Reads pre-generated BigQuery lineage files (optional, for cross-project tracing)
3. Analyzes business logic complexity in each model
4. Classifies models by complexity (LOW/MEDIUM/HIGH)
5. Determines migration priorities (Priority 1-4)
6. Generates comprehensive migration analysis document

## Input Requirements

### Lineage Generation

Lineage files must be generated before running the analyzer:

**DBT Lineage** (Required):
- Automatically generated by `/migrate-cookbook-generator` if missing
- Manual generation: `python lineage_analyzer/dbt_based/analyze_dbt_lineage.py`
- Output: `lineage_analyzer/outputs/lineage_dbt_{model_name}.md`

**BigQuery Lineage** (Optional):
- Traces physical table lineage via BigQuery Data Lineage API (Dataplex)
- Manual generation: `python lineage_analyzer/dataplex_based/analyze_bq_lineage.py project.dataset.table`
- Output: `lineage_analyzer/outputs/lineage_bq_{table_name}.json` and `.md`
- Requires: `google-cloud-datacatalog-lineage` package, Dataplex API enabled

### Primary Input 1: DBT Lineage File

**Location**: `lineage_analyzer/outputs/lineage_dbt_{model_name}.md`

**Source**: Pre-generated from DBT manifest.json via `analyze_dbt_lineage.py`

**Purpose**: Understand model dependencies within DBT project

**Extract From This File**:
- All models in silver/ that target model depends on
- All models in gold/ that target model depends on
- All seed files referenced
- Source references (`{{ source('schema', 'table') }}`)
- Complete dependency chain

### Primary Input 2: BigQuery Lineage File (Optional)

**Location**: `lineage_analyzer/outputs/lineage_bq_{table_name}.json` or `.md`

**Source**: Pre-generated from BigQuery Data Lineage API via `analyze_bq_lineage.py`

**Purpose**: Trace physical table lineage across GCP projects

**Extract From This File**:
- Upstream source tables by level (Level 1, 2, 3...)
- Cross-project dependencies (foreign project tables)
- Table naming patterns across projects
- Physical lineage beyond DBT manifest scope

**Key Pattern**:
```
Level 3: project-a.schema.source_table
Level 2: project-b.schema.intermediate_table
Level 1: project-c.schema.target_table
```

### Required Files
- DBT lineage file: `{{ config.outputs.lineage }}/lineage_dbt_{model_name}.md`
- Configuration file: `config/migration_config.yaml`
- BigQuery lineage file (optional): `{{ config.outputs.lineage }}/lineage_bq_{table_name}.json`

### Required Config Values
```yaml
gcp:
  billing_project: "your-billing-project"  # For API calls
  projects:
    bronze: "your-bronze-project"    # Raw data ingestion
    silver: "your-silver-project"    # Transformed/cleaned data
    gold: "your-gold-project"        # Curated business data

dbt:
  silver_models: "models/silver"     # Transformed models
  gold_models: "models/gold"         # Curated gold models

outputs:
  lineage: "lineage_analyzer/outputs"
  prd: "prd_generator/outputs"
```

## Analysis Process

### Phase 1: Load Configuration

```
Read config/migration_config.yaml

Extract:
- BILLING_PROJECT = config.gcp.billing_project
- SILVER_PROJECT = config.gcp.projects.silver
- GOLD_PROJECT = config.gcp.projects.gold
- SILVER_PATH = config.dbt.silver_models
- GOLD_PATH = config.dbt.gold_models
- LINEAGE_OUTPUT = config.outputs.lineage
```

### Phase 2: Study Lineage Documentation

1. Read DBT lineage file (`lineage_dbt_{model_name}.md`)
2. Read BigQuery lineage file if available (`lineage_bq_{table_name}.json` or `.md`)
3. Identify all dependencies:
   - Silver models (in SILVER_PATH)
   - Gold models (in GOLD_PATH)
   - Seed files
   - Cross-project upstream tables (from BQ lineage)
4. Create complete dependency inventory

**Combining DBT and BQ Lineage**:
- DBT lineage shows dependencies within the DBT project (refs, sources)
- BQ lineage shows physical upstream tables across GCP projects
- Use both to understand full data flow from source to target

### Phase 3: Analyze Each Model

For each silver model:

1. **Read the SQL file**
2. **Identify business logic patterns**:
   - Deduplication: `ROW_NUMBER() OVER(PARTITION BY ...)`
   - CASE statements: Count and categorize
   - Field transformations: SUBSTR, CONCAT, CAST
   - Joins: Multi-source enrichment
   - Aggregations: GROUP BY, COUNT, SUM

3. **Extract source tables**:
   - Parse `{{ source('schema', 'table') }}`
   - Map to: `{SILVER_PROJECT}.schema.table`

### Phase 4: Classify Complexity

| Complexity | Criteria |
|------------|----------|
| **LOW** | Simple field selection, basic deduplication, < 5 CASE statements, no joins |
| **MEDIUM** | 5-15 CASE statements, moderate transformations, simple joins |
| **HIGH** | 15+ CASE statements, pivots, multi-source joins, complex aggregations |

### Phase 5: Determine Priorities

| Priority | Criteria |
|----------|----------|
| **Priority 1** | LOW complexity, no silver dependencies |
| **Priority 2** | MEDIUM complexity, no silver dependencies |
| **Priority 3** | HIGH complexity, no silver dependencies |
| **Priority 4** | Any complexity, requires base dependencies first |

### Phase 6: Generate Analysis Document

**Output Structure**:

```markdown
# Migration Analysis: {model_name}

## 1. Executive Summary
- Total dependencies: X
- Migration scope: Y models
- Key findings

## 2. Dependency Inventory
- Silver models: [list]
- Gold models: [list]
- Seeds: [list]

## 3. Transformation Analysis
For each model:
- Name
- Source
- Business logic summary
- Complexity: LOW/MEDIUM/HIGH
- Recommendation: MOVE/KEEP/EVALUATE

## 4. Migration Recommendations
### Priority 1 (Immediate)
- Model list with rationale

### Priority 2 (Secondary)
- Model list with rationale

### Priority 3 (Advanced)
- Model list with rationale

### Priority 4 (Future)
- Model list with rationale

## 5. Success Metrics
- Row count parity targets
- Validation criteria

## 6. Implementation Plan
- Phase breakdown
- Expected benefits

## 7. Risk Assessment
- Identified risks
- Mitigation strategies

## 8. Conclusion
- Summary and next steps
```

## Output

**File**: `{{ config.outputs.prd }}/{model_name}_migration_analysis.md`

## Complexity Scoring Reference

### Transformation Patterns

| Pattern | Score |
|---------|-------|
| Simple SELECT | 0 |
| Basic WHERE clause | 1 |
| CASE statement (each) | 2 |
| ROW_NUMBER deduplication | 3 |
| Simple JOIN | 4 |
| Multi-table JOIN | 6 |
| Window function | 4 |
| PIVOT/UNPIVOT | 8 |
| Complex aggregation | 5 |

### Scoring Thresholds

| Total Score | Complexity |
|-------------|------------|
| 0-10 | LOW |
| 11-25 | MEDIUM |
| 26+ | HIGH |

## Best Practices

1. **Read Every SQL File**: Don't guess business logic
2. **Be Conservative**: When in doubt, classify higher
3. **Use Config Values**: All project references from config
4. **Document Everything**: Include all findings
5. **Clear Recommendations**: Explicit MOVE/KEEP/EVALUATE

## BigQuery Lineage Generation

For cross-project lineage tracing, use the BigQuery Data Lineage API script:

### Prerequisites

```bash
# Install dependency
pip install google-cloud-datacatalog-lineage

# Enable Dataplex API in your project
gcloud services enable datalineage.googleapis.com --project=YOUR_PROJECT

# Grant lineage viewer role
gcloud projects add-iam-policy-binding YOUR_PROJECT \
    --member="user:your-email@example.com" \
    --role="roles/datalineage.viewer"
```

### Usage

```bash
# Basic usage
python lineage_analyzer/dataplex_based/analyze_bq_lineage.py project.dataset.table

# With options
python lineage_analyzer/dataplex_based/analyze_bq_lineage.py project.dataset.table \
    --location us \
    --foreign-project-depth 3 \
    --output-format all \
    --output-dir lineage_analyzer/outputs

# Simple depth limiting (overrides project-aware logic)
python lineage_analyzer/dataplex_based/analyze_bq_lineage.py project.dataset.table \
    --max-depth 5
```

### Output Files

- **JSON**: `lineage_bq_{table}.json` - Machine-readable lineage data
- **Markdown**: `lineage_bq_{table}.md` - Human-readable report with tree view
- **Console**: Summary printed to terminal

### Project-Aware Depth Limiting

The script supports intelligent depth limiting based on project boundaries:
- Unlimited traversal within the home project
- After encountering a foreign project, continues for +N more levels (default: +3)
- Use `--max-depth` to override with simple depth limiting

---

**Cookbook Version**: 2.1 (Generic with BQ Lineage)
**Configuration**: config/migration_config.yaml
**Output**: Migration analysis document
